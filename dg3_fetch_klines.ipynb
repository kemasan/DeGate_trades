{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ba990c-75cf-480b-94fb-be482c5ba2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests import Request\n",
    "import json\n",
    "import csv\n",
    "import dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from flipside import Flipside\n",
    "import logging\n",
    "# from degate.spot import Spot as Client\n",
    "# from degate.lib.utils import config_logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb961bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "dotenv.load_dotenv('../../.env')\n",
    "api_key = os.environ[\"DUNE_API_KEY\"]\n",
    "headers = {\"X-Dune-API-Key\": api_key}\n",
    "flipside_key = os.environ[\"FLIPSIDE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aff14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28/02 last version to fetch trading data and pass it to clean_and_prepare_data function\n",
    "import time\n",
    "import logging\n",
    "from ipynb.fs.full.dg5_get_close_time import get_latest_close_time, get_end_time_calculation\n",
    "from ipynb.fs.full.dg4_clean_prepare_insert import clean_and_prepare_data\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "# Constants\n",
    "BASE_URL_KLINES = \"https://v1-mainnet-backend.degate.com/order-book-ws-api/klines\"\n",
    "GRANULARITY = 86400  \n",
    "# START_TIME = 1699746810000 # contract creation time https://etherscan.io/tx/0x2306cd22386d3da63eb51edad872495f5f905996df5a0965c6d28cb66948d7aa \n",
    "# END_TIME = 1740139172000 # FEB 21, 11:59:59 PM   \n",
    "\n",
    "# Load valid trading pairs\n",
    "pairs_df = pd.read_csv(\"valid_trading_pairs.csv\")\n",
    "\n",
    "# Session for API reuse\n",
    "session = requests.Session()\n",
    "\n",
    "def fetch_trading_data_by_pair(pair, base_id, quote_id, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Fetch trading data for a given pair using session.\n",
    "    \"\"\"\n",
    "    # pair, base_id, quote_id = pair_data[\"pair\"], pair_data[\"base_id\"], pair_data[\"quote_id\"]\n",
    "    \n",
    "    params = {\n",
    "        \"base_token_id\": base_id,\n",
    "        \"quote_token_id\": quote_id,\n",
    "        \"granularity\": GRANULARITY,\n",
    "        \"start\": start_time, #START_TIME,\n",
    "        \"end\": end_time #END_TIME\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = session.get(BASE_URL_KLINES, params=params, timeout=3)\n",
    "        response.raise_for_status()\n",
    "        result = response.json().get(\"data\", [])\n",
    "\n",
    "        if not result:\n",
    "            return None\n",
    "\n",
    "        df = pd.DataFrame(result)\n",
    "\n",
    "        # Keep only expected columns (ignoring extra ones)\n",
    "        # df = df[[col for col in df.columns if col in columns]]\n",
    "        df.insert(0, \"pair\", pair) \n",
    "        # print(df)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {pair}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_all_trading_data(start_time=None, end_time=None, output_file=None):    \n",
    "    all_data = []\n",
    "\n",
    "    # allows multiple API requests to run concurrently, improving performance\n",
    "    with ThreadPoolExecutor(max_workers=min(10, len(pairs_df))) as executor:\n",
    "        \n",
    "        # stores async results as a key and tradig pair as a value\n",
    "        futures = { \n",
    "            # submits API call for each pair\n",
    "            executor.submit(fetch_trading_data_by_pair, row[\"pair\"], row[\"base_id\"], row[\"quote_id\"], start_time, end_time): row[\"pair\"]\n",
    "            for _, row in pairs_df.iterrows()\n",
    "            }\n",
    "        # collecting results form API calls\n",
    "        for future in as_completed(futures):\n",
    "            # gets the returned data and add it to all_data if not None\n",
    "            if (result := future.result()) is not None:\n",
    "                all_data.append(result)\n",
    "   \n",
    "   # Saving the data to a CSV file\n",
    "    if all_data:\n",
    "        # Generate a unique filename if none is provided\n",
    "        if output_file is None:\n",
    "            timestamp = time.strftime(\"%Y%m%d_%H%M%S\")  # Example: 20250228_165430\n",
    "            output_file = f\"trading_data_{timestamp}.csv\"\n",
    "\n",
    "        pd.concat(all_data, ignore_index=True).to_csv(output_file, index=False) #test_raw_trading_data.csv\n",
    "        print(f\"INFO: Saved trading data to {output_file}.\")\n",
    "\n",
    "        # Pass the output file to the next function for further processing\n",
    "        clean_and_prepare_data(output_file)\n",
    "    \n",
    "        return output_file\n",
    "    \n",
    "    else:\n",
    "        logging.warning(\"No trading data retrieved.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860a0127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 15:54:36,448 - INFO - File trading_data_20250302_155435.csv loaded successfully with shape (55972, 14)\n",
      "2025-03-02 15:54:36,453 - INFO - Columns renamed successfully. New columns: ['pair', 'date', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades', 'taker_buy_base_vol', 'taker_buy_quote_vol', 'ignore', '_avg_price']\n",
      "2025-03-02 15:54:36,458 - INFO - Columns dropped successfully. New columns: ['pair', 'date', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Saved trading data to trading_data_20250302_155435.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 15:54:36,928 - INFO - Intermediate file saved as: None\n",
      "2025-03-02 15:54:36,935 - INFO - Converted 'date' and 'close_time' to datetime format.\n",
      "2025-03-02 15:54:37,823 - INFO - Data cleaned and prepared for upload to Dune.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trading_data_20250302_155435.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, fetch all trading data from the beginning of times\n",
    "fetch_all_trading_data(1699746810000, 1740139172000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20900d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 15:54:44,021 - INFO - Latest close_time found: 1740182399999\n",
      "2025-03-02 15:54:50,959 - INFO - File trading_data_20250302_155450.csv loaded successfully with shape (1365, 14)\n",
      "2025-03-02 15:54:50,960 - INFO - Columns renamed successfully. New columns: ['pair', 'date', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades', 'taker_buy_base_vol', 'taker_buy_quote_vol', 'ignore', '_avg_price']\n",
      "2025-03-02 15:54:50,961 - INFO - Columns dropped successfully. New columns: ['pair', 'date', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_volume', 'trades']\n",
      "2025-03-02 15:54:50,975 - INFO - Intermediate file saved as: None\n",
      "2025-03-02 15:54:50,979 - INFO - Converted 'date' and 'close_time' to datetime format.\n",
      "2025-03-02 15:54:51,006 - INFO - Data cleaned and prepared for upload to Dune.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Saved trading data to trading_data_20250302_155450.csv.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'trading_data_20250302_155450.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fetch_all_trading_data((get_latest_close_time() + 1000), get_end_time_calculation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82a20a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trading_data_20250302_155450.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "file = sorted(glob.glob(\"trading_data_*.csv\"))[-1]\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea15bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>RSR/USDC</td>\n",
       "      <td>1740787200000</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1740873599999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pair              0         1         2         3         4    5  \\\n",
       "1364  RSR/USDC  1740787200000  0.008297  0.008297  0.008297  0.008297  0.0   \n",
       "\n",
       "                  6    7  8    9   10    11   12  \n",
       "1364  1740873599999  0.0  0  0.0  0.0  True  0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = pd.read_csv(sorted(glob.glob(\"trading_data_*.csv\"))[-1])\n",
    "tst.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e61046",
   "metadata": {},
   "source": [
    "NEXT STEP: automatization\n",
    "- call token check functions\n",
    "- call fetc_all_trading_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6e076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
