{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ba990c-75cf-480b-94fb-be482c5ba2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests import Request\n",
    "import json\n",
    "import csv\n",
    "import dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from flipside import Flipside\n",
    "import logging\n",
    "import time\n",
    "# from degate.spot import Spot as Client\n",
    "# from degate.lib.utils import config_logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63333162",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "dotenv.load_dotenv('../../.env')\n",
    "api_key = os.environ[\"DUNE_API_KEY\"]\n",
    "headers = {\"X-Dune-API-Key\": api_key}\n",
    "flipside_key = os.environ[\"FLIPSIDE_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28/02 last version to clean and prepare trading data to be uploaded to Dune\n",
    "import time\n",
    "def clean_and_prepare_data(input_file):\n",
    "    \"\"\"\n",
    "    Clean and prepare the trading data from the input file.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(input_file)\n",
    "        logging.info(f\"File {input_file} loaded successfully with shape {df.shape}\")\n",
    "\n",
    "        base = df.copy()\n",
    "        # logging.info(\"Dataframe copied for transformation.\")\n",
    "        base.rename(columns={'0':'date','1':'open','2':'high','3':'low','4':'close','5':'volume','6':'close_time',\n",
    "                            '7':'quote_volume','8':'trades','9':'taker_buy_base_vol','10':'taker_buy_quote_vol',\n",
    "                            '11':'ignore','12':'_avg_price'}, inplace=True)\n",
    "        logging.info(f\"Columns renamed successfully. New columns: {list(base.columns)}\")\n",
    "\n",
    "        base = base.drop(['taker_buy_base_vol','taker_buy_quote_vol','ignore','_avg_price'], axis=1)\n",
    "        logging.info(f\"Columns dropped successfully. New columns: {list(base.columns)}\")\n",
    "    \n",
    "        # Save file with timestamps to use for taking the close_time for the next fetching of trading data\n",
    "        last_update = base.to_csv('test_degate_trades_updates.csv', index=False)\n",
    "        logging.info(f\"Intermediate file saved as: {last_update}\")\n",
    "\n",
    "        # Prepare df for further uploads\n",
    "        base['date'] = pd.to_datetime(base['date'], unit='ms')\n",
    "        base['close_time'] = pd.to_datetime(base['close_time'], unit='ms')\n",
    "        logging.info(f\"Converted 'date' and 'close_time' to datetime format.\")\n",
    "\n",
    "        # Save the final cleaned data to a new file\n",
    "        base.to_csv(f'degate_updates_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv', index=False)\n",
    "        logging.info(f\"Data cleaned and prepared for upload to Dune.\")\n",
    "        \n",
    "        return base\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during data cleaning process: {e}\", exc_info=True)\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Step 3: Upload the data to Dune \n",
    "# url = \"https://api.dune.com/api/v1/table/kemasan/degate_trades/insert\"\n",
    "# headers = {\n",
    "#     \"X-DUNE-API-KEY\": api_key,\n",
    "#     \"Content-Type\": \"text/csv\"\n",
    "# }\n",
    "\n",
    "# with open(f\"degate_updates_{time.strftime('%Y%m%d_%H%M%S')}.csv\", \"rb\") as data:\n",
    "#     response = requests.request(\"POST\", url, data=data, headers=headers)\n",
    "\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92abf27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02.03 test \n",
    "def update_dune_table(df):\n",
    "    \"\"\"\n",
    "    Insert new trading data to Dune table.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure the DataFrame is saved to a CSV file\n",
    "        output_file = f'degate_updates_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "        df.to_csv(output_file, index=False)\n",
    "\n",
    "        # Set the URL and headers for Dune API\n",
    "        url = \"https://api.dune.com/api/v1/table/kemasan/degate_trades/insert\"\n",
    "        headers = {\n",
    "            \"X-DUNE-API-KEY\": api_key,\n",
    "            \"Content-Type\": \"text/csv\"\n",
    "        }\n",
    "\n",
    "        # Upload the CSV to Dune\n",
    "        with open(output_file, \"rb\") as data:\n",
    "            response = requests.request(\"POST\", url, data=data, headers=headers)\n",
    "\n",
    "        # Check the response status\n",
    "        if response.status_code == 200:\n",
    "            logging.info(f\"Data uploaded successfully to Dune. Response: {response.text}\")\n",
    "        else:\n",
    "            logging.error(f\"Error uploading data to Dune. Response: {response.text}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during upload to Dune: {e}\", exc_info=True)\n",
    "    return None\n",
    "\n",
    "def main(input_file):\n",
    "    # Clean and prepare the data\n",
    "    cleaned_data = clean_and_prepare_data(input_file)\n",
    "    \n",
    "    # If data was successfully cleaned, upload it to Dune\n",
    "    if cleaned_data is not None:\n",
    "        update_dune_table(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2/03/25 gpt version\n",
    "# def clean_and_prepare_data(input_file):\n",
    "#     \"\"\"\n",
    "#     Clean and prepare the trading data from the input file.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         df = pd.read_csv(input_file)\n",
    "#         logging.info(f\"File {input_file} loaded successfully with shape {df.shape}\")\n",
    "\n",
    "#         base = df.copy()\n",
    "#         base.rename(columns={'0':'date','1':'open','2':'high','3':'low','4':'close','5':'volume','6':'close_time',\n",
    "#                              '7':'quote_volume','8':'trades','9':'taker_buy_base_vol','10':'taker_buy_quote_vol',\n",
    "#                              '11':'ignore','12':'_avg_price'}, inplace=True)\n",
    "#         logging.info(f\"Columns renamed successfully. New columns: {list(base.columns)}\")\n",
    "\n",
    "#         base = base.drop(['taker_buy_base_vol','taker_buy_quote_vol','ignore','_avg_price'], axis=1)\n",
    "#         logging.info(f\"Columns dropped successfully. New columns: {list(base.columns)}\")\n",
    "\n",
    "#         # Save intermediate file with timestamps to use for close_time for next fetch\n",
    "#         base.to_csv('test_degate_trades_updates.csv', index=False)\n",
    "#         logging.info(f\"Intermediate file saved as: test_degate_trades_updates.csv\")\n",
    "\n",
    "#         # Convert timestamps to datetime format\n",
    "#         base['date'] = pd.to_datetime(base['date'], unit='ms')\n",
    "#         base['close_time'] = pd.to_datetime(base['close_time'], unit='ms')\n",
    "#         logging.info(f\"Converted 'date' and 'close_time' to datetime format.\")\n",
    "\n",
    "#         # Save cleaned data to a new file\n",
    "#         base.to_csv(f'degate_updates_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv', index=False)\n",
    "#         logging.info(f\"Data cleaned and prepared for upload to Dune.\")\n",
    "\n",
    "#         # Return cleaned DataFrame for further processing\n",
    "#         return base\n",
    "\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error during data cleaning process: {e}\", exc_info=True)\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def upload_to_dune(data):\n",
    "#     \"\"\"\n",
    "#     Upload the cleaned data to Dune Analytics.\n",
    "#     This is a placeholder function, you need to implement the upload logic here.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Example: Upload the data to Dune (replace with actual upload code)\n",
    "#         logging.info(\"Uploading data to Dune...\")\n",
    "#         # Your upload logic goes here\n",
    "#         logging.info(f\"Successfully uploaded data: {data.shape[0]} rows.\")\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"Error during uploading process: {e}\", exc_info=True)\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     # Assume `output_file` is the file generated in your earlier process\n",
    "#     output_file = \"trading_data.csv\"  # Update with actual filename if needed\n",
    "\n",
    "#     # Clean and prepare data\n",
    "#     cleaned_data = clean_and_prepare_data(output_file)\n",
    "    \n",
    "#     if cleaned_data is not None:\n",
    "#         # Upload the cleaned data to Dune\n",
    "#         upload_to_dune(cleaned_data)\n",
    "#     else:\n",
    "#         logging.warning(\"No data to upload to Dune.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6e076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
